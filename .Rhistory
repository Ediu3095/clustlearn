sigma <- sapply(
seq_len(k),
function(i) cov.wt(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
?mean
?rowMeans
# Perform k-means to get initial values for mu, sigma and pi
members <- kmeans(data, k)
mu <- t(members$centers)
sigma <- sapply(
seq_len(k),
function(i) cov(data[members$cluster == i, , drop = FALSE]),
simplify = "array"
)
lambda <- members$size / nrow(data)
# EM algorithm
# starting values of expected value of the log likelihood
q <- c(
0,
sum(
sapply(
seq_len(k),
function(i) log(lambda[i]) + log(dmnorm(data, mu[, i], sigma[, , i]))
)
)
)
sum.finite <- function(x) {
sum(x[is.finite(x)])
}
rowSums.finite <- function(x) {
rowSums(x[is.finite(colSums(x)), , drop = FALSE])
}
colSums.finite <- function(x) {
colSums(x[, is.finite(rowSums(x)), drop = FALSE])
}
# EM algorithm
# starting values of expected value of the log likelihood
q <- c(
0,
sum.finite(
sapply(
seq_len(k),
function(i) log(lambda[i]) + log(dmnorm(data, mu[, i], sigma[, , i]))
)
)
)
# E step
comp <- sapply(
seq_len(k),
function(i) lambda[i] * dmnorm(data, mu[, i], sigma[, , i])
)
comp_sum <- rowSums(comp)
p <- comp / comp_sum
comp_sum <- rowSums.finite(comp)
# M step
lambda <- sapply(
seq_len(k),
function(i) sum.finite(p[, i]) / nrow(data)
)
mu <- sapply(
seq_len(k),
function(i) colSums.finite(p[, i] * data) / sum(p[, i])
)
sigma <- sapply(
seq_len(k),
function(i) cov.wt(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
rowSums(comp)
rowSums.finite <- function(x) {
rowSums(x[, is.finite(colSums(x)), drop = FALSE])
}
colSums.finite <- function(x) {
colSums(x[is.finite(rowSums(x)), , drop = FALSE])
}
# Perform k-means to get initial values for mu, sigma and pi
members <- kmeans(data, k)
mu <- t(members$centers)
sigma <- sapply(
seq_len(k),
function(i) cov(data[members$cluster == i, , drop = FALSE]),
simplify = "array"
)
lambda <- members$size / nrow(data)
# EM algorithm
# starting values of expected value of the log likelihood
q <- c(
0,
sum.finite(
sapply(
seq_len(k),
function(i) log(lambda[i]) + log(dmnorm(data, mu[, i], sigma[, , i]))
)
)
)
# E step
comp <- sapply(
seq_len(k),
function(i) lambda[i] * dmnorm(data, mu[, i], sigma[, , i])
)
comp_sum <- rowSums.finite(comp)
p <- comp / comp_sum
# M step
lambda <- sapply(
seq_len(k),
function(i) sum.finite(p[, i]) / nrow(data)
)
mu <- sapply(
seq_len(k),
function(i) colSums.finite(p[, i] * data) / sum(p[, i])
)
sigma <- sapply(
seq_len(k),
function(i) cov.wt(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
q <- c(q[2], sum(log(comp_sum)))
while (abs(diff(q)) >= 1e-6) {
# E step
comp <- sapply(
seq_len(k),
function(i) lambda[i] * dmnorm(data, mu[, i], sigma[, , i])
)
comp_sum <- rowSums.finite(comp)
p <- comp / comp_sum
# M step
lambda <- sapply(
seq_len(k),
function(i) sum.finite(p[, i]) / nrow(data)
)
mu <- sapply(
seq_len(k),
function(i) colSums.finite(p[, i] * data) / sum(p[, i])
)
sigma <- sapply(
seq_len(k),
function(i) cov.wt(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
q <- c(q[2], sum(log(comp_sum)))
}
abs(diff(q)) >= 1e-6
q
# Perform k-means to get initial values for mu, sigma and pi
members <- kmeans(data, k)
mu <- t(members$centers)
sigma <- sapply(
seq_len(k),
function(i) cov(data[members$cluster == i, , drop = FALSE]),
simplify = "array"
)
lambda <- members$size / nrow(data)
# EM algorithm
# starting values of expected value of the log likelihood
q <- c(
0,
sum.finite(
sapply(
seq_len(k),
function(i) log(lambda[i]) + log(dmnorm(data, mu[, i], sigma[, , i]))
)
)
)
it <- 0
while (abs(diff(q)) >= 1e-6) {
# E step
comp <- sapply(
seq_len(k),
function(i) lambda[i] * dmnorm(data, mu[, i], sigma[, , i])
)
comp_sum <- rowSums.finite(comp)
p <- comp / comp_sum
# M step
lambda <- sapply(
seq_len(k),
function(i) sum.finite(p[, i]) / nrow(data)
)
mu <- sapply(
seq_len(k),
function(i) colSums.finite(p[, i] * data) / sum(p[, i])
)
sigma <- sapply(
seq_len(k),
function(i) cov.wt(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
q <- c(q[2], sum(log(comp_sum)))
it <- it + 1
}
View(mu)
plot(data)
x <- seq(-1, 1, .1)
y <- seq(-1, 1, .1)
m <- mu[,3]
s <- sigma[,,3]
f <- function(x, y) dmnorm(cbind(x, y), m, s)
z <- outer(x, y, f)
contour(x, y, z)
x <- seq(-2, 3, .01)
y <- seq(-2, 3, .01)
z <- outer(x, y, f)
y <- seq(-2, 3, .05)
x <- seq(-2, 3, .05)
x <- seq(-1, 2, .05)
y <- seq(-1, 2, .05)
z <- outer(x, y, f)
contour(x, y, z)
x <- seq(-.5, 1.5, .025)
z <- outer(x, y, f)
contour(x, y, z)
x <- seq(-.1, 1.1, .0125)
contour(x, y, z)
z <- outer(x, y, f)
contour(x, y, z)
install.library(mnormt)
install.library('mnormt')
install.packages('mnormt')
library(mnormt)
f <- function(x, y) mnormt::dmnorm(cbind(x, y), m, s)
z <- outer(x, y, f)
contour(x, y, z)
data <- read.csv('C:\\Users\\3arci\\Desktop\\papers\\databases\\db5.csv')
k <- 3
# Perform k-means to get initial values for mu, sigma and pi
members <- kmeans(data, k)
mu <- t(members$centers)
sigma <- sapply(
seq_len(k),
function(i) cov(data[members$cluster == i, , drop = FALSE]),
simplify = "array"
)
lambda <- members$size / nrow(data)
# EM algorithm
# Starting values of expected value of the log likelihood
q <- c(
0,
sum.finite(
sapply(
seq_len(k),
function(i) log(lambda[i]) + log(mnormt::dmnorm(data, mu[, i], sigma[, , i]))
)
)
)
it <- 0
while (abs(diff(q)) >= 1e-6) {
# E step
comp <- sapply(
seq_len(k),
function(i) lambda[i] * mnormt::dmnorm(data, mu[, i], sigma[, , i])
)
comp_sum <- rowSums.finite(comp)
p <- comp / comp_sum
# M step
lambda <- sapply(
seq_len(k),
function(i) sum.finite(p[, i]) / nrow(data)
)
mu <- sapply(
seq_len(k),
function(i) colSums.finite(p[, i] * data) / sum(p[, i])
)
sigma <- sapply(
seq_len(k),
function(i) cov.wt.finite(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
# Compute new expected value of the log likelihood
q <- c(q[2], sum(log(comp_sum)))
it <- it + 1
}
# EM algorithm
# Starting values of expected value of the log likelihood
q <- c(
0,
sum.finite(
sapply(
seq_len(k),
function(i) log(lambda[i]) + log(mnormt::dmnorm(data, mu[, i], sigma[, , i]))
)
)
)
# Finite versions of sum, rowSums, colSums and cov.wt
sum.finite <- function(x) {
sum(x[is.finite(x)])
}
rowSums.finite <- function(x) {
rowSums(x[, is.finite(colSums(x)), drop = FALSE])
}
colSums.finite <- function(x) {
colSums(x[is.finite(rowSums(x)), , drop = FALSE])
}
cov.wt.finite <- function(x, wt, center) {
cov.wt(x[is.finite(wt), , drop = FALSE], wt[is.finite(wt)], center)
}
# EM algorithm
# Starting values of expected value of the log likelihood
q <- c(
0,
sum.finite(
sapply(
seq_len(k),
function(i) log(lambda[i]) + log(mnormt::dmnorm(data, mu[, i], sigma[, , i]))
)
)
)
it <- 0
while (abs(diff(q)) >= 1e-6) {
# E step
comp <- sapply(
seq_len(k),
function(i) lambda[i] * mnormt::dmnorm(data, mu[, i], sigma[, , i])
)
comp_sum <- rowSums.finite(comp)
p <- comp / comp_sum
# M step
lambda <- sapply(
seq_len(k),
function(i) sum.finite(p[, i]) / nrow(data)
)
mu <- sapply(
seq_len(k),
function(i) colSums.finite(p[, i] * data) / sum(p[, i])
)
sigma <- sapply(
seq_len(k),
function(i) cov.wt.finite(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
# Compute new expected value of the log likelihood
q <- c(q[2], sum(log(comp_sum)))
it <- it + 1
}
# E step
comp <- sapply(
seq_len(k),
function(i) lambda[i] * mnormt::dmnorm(data, mu[, i], sigma[, , i])
)
comp_sum <- rowSums.finite(comp)
p <- comp / comp_sum
# M step
lambda <- sapply(
seq_len(k),
function(i) sum.finite(p[, i]) / nrow(data)
)
mu <- sapply(
seq_len(k),
function(i) colSums.finite(p[, i] * data) / sum(p[, i])
)
sigma <- sapply(
seq_len(k),
function(i) cov.wt.finite(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
data <- read.csv('C:\\Users\\3arci\\Desktop\\papers\\databases\\db5.csv')
k <- 3
# Finite versions of sum, rowSums, colSums and cov.wt
sum.finite <- function(x) {
sum(x[is.finite(x)])
}
rowSums.finite <- function(x) {
rowSums(x[, is.finite(colSums(x)), drop = FALSE])
}
colSums.finite <- function(x) {
colSums(x[is.finite(rowSums(x)), , drop = FALSE])
}
cov.wt.finite <- function(x, wt, center) {
finites <- is.finite(wt)
cov.wt(x[finites, , drop = FALSE], wt[finites], center)
}
# Perform k-means to get initial values for mu, sigma and pi
members <- kmeans(data, k)
mu <- t(members$centers)
sigma <- sapply(
seq_len(k),
function(i) cov(data[members$cluster == i, , drop = FALSE]),
simplify = "array"
)
lambda <- members$size / nrow(data)
# EM algorithm
# Starting values of expected value of the log likelihood
q <- c(
0,
sum.finite(
sapply(
seq_len(k),
function(i) log(lambda[i]) + log(mnormt::dmnorm(data, mu[, i], sigma[, , i]))
)
)
)
it <- 0
# E step
comp <- sapply(
seq_len(k),
function(i) lambda[i] * mnormt::dmnorm(data, mu[, i], sigma[, , i])
)
comp_sum <- rowSums.finite(comp)
p <- comp / comp_sum
matrix(1:10, ncol = 2)
matrix(1:10, ncol = 2) - c(1, 2, 3, 4, 5)
matrix(1:10, ncol = 2) - c(1, 2)
# M step
lambda <- sapply(
seq_len(k),
function(i) sum.finite(p[, i]) / nrow(data)
)
mu <- sapply(
seq_len(k),
function(i) colSums.finite(p[, i] * data) / sum(p[, i])
)
sigma <- sapply(
seq_len(k),
function(i) cov.wt.finite(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
View(p)
data <- as.matrix(data)
# Perform k-means to get initial values for mu, sigma and pi
members <- kmeans(data, k)
mu <- t(members$centers)
sigma <- sapply(
seq_len(k),
function(i) cov(data[members$cluster == i, , drop = FALSE]),
simplify = "array"
)
lambda <- members$size / nrow(data)
# EM algorithm
# Starting values of expected value of the log likelihood
q <- c(
0,
sum.finite(
sapply(
seq_len(k),
function(i) log(lambda[i]) + log(mnormt::dmnorm(data, mu[, i], sigma[, , i]))
)
)
)
it <- 0
# E step
comp <- sapply(
seq_len(k),
function(i) lambda[i] * mnormt::dmnorm(data, mu[, i], sigma[, , i])
)
comp_sum <- rowSums.finite(comp)
p <- comp / comp_sum
# M step
lambda <- sapply(
seq_len(k),
function(i) sum.finite(p[, i]) / nrow(data)
)
mu <- sapply(
seq_len(k),
function(i) colSums.finite(p[, i] * data) / sum(p[, i])
)
sigma <- sapply(
seq_len(k),
function(i) cov.wt.finite(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
sigma <- sapply(
seq_len(k),
function(i) cov.wt(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
sigma <- sapply(
seq_len(k),
function(i) cov.wt.finite(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
cov.wt.finite <- function(x, wt, center) {
cov.wt(x[is.finite(wt), , drop = FALSE], wt[is.finite(wt)], center)
}
sigma <- sapply(
seq_len(k),
function(i) cov.wt.finite(data, wt = p[, i], center = mu[, i])$cov,
simplify = "array"
)
# Perform k-means to get initial values for mu, sigma and pi
members <- kmeans(data, k)
mu <- t(members$centers)
sigma <- sapply(
seq_len(k),
function(i) cov(data[members$cluster == i, , drop = FALSE]),
simplify = "array"
)
lambda <- members$size / nrow(data)
x <- seq(-3, 3, .1)
y <- seq(-3, 3, .1)
(m <- mu[,3])
(s <- sigma[,,3])
f <- function(x, y) dmnorm(cbind(x, y), m, s)
z <- outer(x, y, f)
contour(x, y, z)
y <- seq(-1.5, -1, .01)
x <- seq(-2, -1, .01)
contour(x, y, z)
z <- outer(x, y, f)
contour(x, y, z)
# x is a matrix where each row is a data point
# mu is a vector
# sigma is a square matrix with sides as big as x has columns
dmnorm <- function(x, mu, sigma) {
k <- ncol(sigma)
x  <- as.matrix(x)
diff <- t(t(x) - mu)
num <- exp(-1 / 2 * diag(diff %*% solve(sigma) %*% t(diff)))
den <- sqrt(((2 * pi)^k) * det(sigma))
num / den
}
f <- function(x, y) dmnorm(cbind(x, y), m, s)
z <- outer(x, y, f)
contour(x, y, z)
